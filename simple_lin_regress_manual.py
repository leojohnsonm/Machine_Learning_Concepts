# -*- coding: utf-8 -*-
"""Simple_Lin_Regress_Manual.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rzGXzQOpr-e_qvlL-Kh5XymyeUAm3h6r
"""

# Simple Linear Regression Manual Vs Scipy Library

# y = mx + c 

# m = slope 
# c = y-intercept

import numpy as np 
import matplotlib.pyplot as plt

x = [1,3,5,9,7,8,11,15,16,19] 
y = [22,31,40,51,55,45,90,93,98,105]

print(len(x),len(y))

# Simple Linear Regression - Manual Calculation starts

# pointed the actual x and y value 

plt.scatter(x,y)

def slreg(x,y):
  mean_x = np.mean(x)
  mean_y = np.mean(y)

  n = len(x)
  num = 0
  denom = 0
  for i in range(n):
    num += (x[i] - mean_x) * (y[i] - mean_y)
    denom += (x[i] - mean_x) ** 2

  m = num/denom
  c = mean_y - m * mean_x
  return m,c

m, c = slreg(x,y)
print("slope = ", m)
print('intercept = ', c)

def reg_line(x):
    return m * x + c

reg = list(map(reg_line,x))

plt.scatter(x,y) # scatter points for given data
plt.plot(x, reg) # plotted for the y_intercept(c) and slope(m)

# Scipy and ScikitLearn Library were implemented here by calling its functions

from scipy import stats 
from sklearn.model_selection import train_test_split

#    Need of R^2 value - the value bw -1 and 1 , let it be considered as good fit for the prediction 

#    On the other hand,the value nearer to 0 like 0.01 or 0.06 it is considered as bad fit for prediction  

#    Find r square value by test-train-split method 


# Predicts the value of y , by slope and intercept 

def predict(x, m, c):
    pred_y = list()
    for i in range(len(x)):
        pred_y.append(c + m * x[i])

    return pred_y


def r2score(y_obs, y_pred):
    yhat = np.mean(y_obs)

    ss_res = 0.0
  
    ss_tot = 0.0

    for i in range(len(y_obs)):
        ss_res += (y_obs[i] - y_pred[i]) ** 2
        ss_tot += (y_obs[i] - yhat) ** 2

    r2 = 1 - (ss_res / ss_tot)

    return r2

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

#for training = 70 % of data taken , for test - 30% of data taken


m, c = slreg(X_train,y_train)
print("slope = ", m)
print('intercept = ', c)


#30 % of test data were used to predict the r_squared value 

y_pred = predict(X_test, m, c)

print("R-squared :", r2score(y_test, y_pred))
print(f"Slope of the given data {m} and Intercept point on the Y_axis {c}")

plt.plot(X_test, y_pred, color='red', label='Linear Regression')
plt.scatter(X_train, y_train, c='b', label='Scatter Plot')

plt.legend()
plt.show()

#Below mentioned order to be used to find all the parameters of the data points 

#All findings were done by scipy and scikitlearn 

slope, intercept, r,p, std_err = stats.linregress(x,y)

print("slope :",slope)
print("intercept :", intercept)
print("r value:",r)
print("p_value: ",p)
print("std_err", std_err)